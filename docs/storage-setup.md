# Configuration du stockage

Guide pour configurer les disques supplÃ©mentaires pour les projets Deep Learning.

## ğŸ“Š Configuration des disques

### Disques disponibles

| Disque | ModÃ¨le | Taille | Type | Utilisation |
|--------|--------|--------|------|-------------|
| **sda** | Kingston SV300S3 | 112 GB | SSD | SystÃ¨me Ubuntu (/) |
| **sdb** | Seagate ST3250318AS | 233 GB | HDD | Non utilisÃ© |
| **sdc** | Intel SSDSA2M160 | 149 GB | SSD | **Stockage projets DL** |

### Ã‰tat actuel
```bash
$ df -h
/dev/mapper/ubuntu--vg-ubuntu--lv   54G   40G   12G  79% /
/dev/sdc1                          150G  7.6G  142G   6% /mnt/data
```

âš ï¸ **Disque systÃ¨me (sda) presque plein** : 79% utilisÃ©, seulement 12 GB libres

âœ… **Disque donnÃ©es (sdc1)** : 142 GB libres pour projets Deep Learning

## ğŸ”§ Montage du disque sdc1

### 1. Installation du support NTFS
```bash
sudo apt install ntfs-3g -y
```

### 2. CrÃ©ation du point de montage
```bash
sudo mkdir -p /mnt/data
```

### 3. Montage manuel
```bash
sudo mount -t ntfs-3g /dev/sdc1 /mnt/data
```

### 4. VÃ©rification
```bash
df -h | grep sdc
ls -la /mnt/data
```

### 5. Configuration des permissions
```bash
sudo chown -R samir:samir /mnt/data
```

### 6. Montage automatique au dÃ©marrage

**Trouver l'UUID du disque :**
```bash
sudo blkid /dev/sdc1
```

RÃ©sultat :
```
/dev/sdc1: LABEL="AMGIO" UUID="BE20A9E20AA5CE1" TYPE="ntfs"
```

**Ã‰diter fstab :**
```bash
sudo nano /etc/fstab
```

**Ajouter Ã  la fin :**
```
# Disque Intel SSD pour projets Deep Learning
UUID=BE20A9E20AA5CE1 /mnt/data ntfs-3g defaults,uid=1000,gid=1000 0 0
```

**Tester le montage :**
```bash
sudo umount /mnt/data
sudo mount -a
df -h | grep sdc
```

## ğŸ“ Structure du projet Deep Learning

### Organisation des dossiers
```bash
/mnt/data/deep-learning/
â”œâ”€â”€ projects/          # Code source des projets
â”œâ”€â”€ datasets/          # Datasets (CIFAR, ImageNet, etc.)
â”œâ”€â”€ models/            # ModÃ¨les prÃ©-entraÃ®nÃ©s tÃ©lÃ©chargÃ©s
â”œâ”€â”€ checkpoints/       # Sauvegardes pendant entraÃ®nement
â””â”€â”€ results/           # RÃ©sultats, logs, graphiques
```

**CrÃ©ation de la structure :**
```bash
mkdir -p /mnt/data/deep-learning/{projects,datasets,models,checkpoints,results}
```

### Lien symbolique pour accÃ¨s rapide
```bash
ln -s /mnt/data/deep-learning ~/dl

# Maintenant accessible via :
cd ~/dl
cd ~/dl/projects
cd ~/dl/datasets
```

## ğŸ–¥ï¸ Configuration VSCode

### Ajouter le disque Ã  l'espace de travail

1. Ouvrir VSCode connectÃ© en SSH
2. `File` â†’ `Add Folder to Workspace`
3. Entrer : `/mnt/data/deep-learning`
4. Cliquer OK

**RÃ©sultat dans l'explorateur :**
```
ğŸ“ SAMIR [SSH: 192.168.1.108]    â† /home/samir/
ğŸ“ deep-learning                  â† /mnt/data/deep-learning/
   ğŸ“ projects
   ğŸ“ datasets
   ğŸ“ models
   ğŸ“ checkpoints
   ğŸ“ results
```

## ğŸ’¾ Utilisation pratique

### CrÃ©er un nouveau projet

**MÃ©thode 1 : Via VSCode**

1. Clic droit sur `deep-learning/projects`
2. New Folder â†’ `mon-projet`
3. New File â†’ `train.py`

**MÃ©thode 2 : Via terminal**
```bash
cd /mnt/data/deep-learning/projects
mkdir mon-nouveau-projet
cd mon-nouveau-projet

# Activer environnement conda
conda activate ml

# CrÃ©er fichiers
touch train.py model.py utils.py
```

### OÃ¹ stocker quoi ?

| Type de fichier | Emplacement | Raison |
|----------------|-------------|--------|
| **Code Python** | `/mnt/data/deep-learning/projects/` | Espace disponible |
| **Datasets** | `/mnt/data/deep-learning/datasets/` | Peut Ãªtre volumineux |
| **Checkpoints** | `/mnt/data/deep-learning/checkpoints/` | Sauvegardes frÃ©quentes |
| **ModÃ¨les prÃ©-entraÃ®nÃ©s** | `/mnt/data/deep-learning/models/` | ResNet, BERT, etc. |
| **Logs TensorBoard** | `/mnt/data/deep-learning/results/runs/` | Historique entraÃ®nements |
| **Scripts systÃ¨me** | `/home/samir/scripts/` | Petits fichiers systÃ¨me |

### Exemple complet
```bash
# CrÃ©er un projet CIFAR-10
cd /mnt/data/deep-learning/projects
mkdir cifar10-classification
cd cifar10-classification

# Activer environnement
conda activate ml

# CrÃ©er structure
mkdir {data,models,logs}
touch train.py model.py dataset.py config.py

# Le dataset sera tÃ©lÃ©chargÃ© automatiquement dans data/
# Les checkpoints dans models/
# Les logs TensorBoard dans logs/
```

## ğŸ“Š Monitoring de l'espace disque

### Voir l'utilisation globale
```bash
df -h
```

### Voir l'utilisation par dossier
```bash
du -h --max-depth=1 /mnt/data/deep-learning/
```

### Trouver les gros fichiers
```bash
# Top 10 des plus gros fichiers
find /mnt/data/deep-learning/ -type f -exec du -h {} + | sort -rh | head -10
```

### Nettoyer l'espace
```bash
# Supprimer les anciens checkpoints
rm -rf /mnt/data/deep-learning/checkpoints/old_experiments/

# Supprimer les datasets non utilisÃ©s
rm -rf /mnt/data/deep-learning/datasets/unused/
```

## âš ï¸ PrÃ©cautions

### Sauvegarde

Le disque sdc1 est en NTFS (format Windows). Si vous reformatez la machine :

âœ… **Avantages NTFS** :
- Lisible sous Windows si vous dÃ©marrez en dual-boot
- Pas besoin de backup pour rÃ©installation Ubuntu

âš ï¸ **InconvÃ©nients NTFS** :
- LÃ©gÃ¨rement moins performant que ext4 (natif Linux)
- Permissions Unix limitÃ©es

### Alternative : Reformater en ext4

Si vous n'avez pas besoin de Windows :
```bash
# âš ï¸ ATTENTION : Efface toutes les donnÃ©es !
sudo umount /mnt/data
sudo mkfs.ext4 /dev/sdc1

# Remonter
sudo mount /dev/sdc1 /mnt/data
```

**Avantages ext4** :
- âœ… Plus rapide (5-10%)
- âœ… Meilleure gestion des permissions
- âœ… Plus stable pour Linux

**InconvÃ©nients ext4** :
- âŒ Non lisible sous Windows

## ğŸ” VÃ©rification de la configuration

### Checklist

- [ ] Disque sdc1 montÃ© sur `/mnt/data`
- [ ] Permissions correctes (propriÃ©taire : samir)
- [ ] Montage automatique configurÃ© dans `/etc/fstab`
- [ ] Structure des dossiers crÃ©Ã©e
- [ ] Lien symbolique `~/dl` crÃ©Ã©
- [ ] VSCode configurÃ© avec les 2 workspaces
- [ ] Test d'Ã©criture rÃ©ussi

### Test d'Ã©criture
```bash
# CrÃ©er un fichier test
echo "Test stockage Deep Learning" > /mnt/data/deep-learning/test.txt

# Lire via diffÃ©rents chemins
cat /mnt/data/deep-learning/test.txt
cat ~/dl/test.txt

# Les deux doivent afficher le mÃªme contenu âœ…
```

## ğŸ“š Commandes utiles
```bash
# Voir tous les disques
lsblk

# DÃ©tails des partitions
sudo fdisk -l

# Espace disque utilisÃ©
df -h

# UUID des disques
sudo blkid

# Taille d'un dossier
du -sh /mnt/data/deep-learning/

# Monter manuellement
sudo mount /dev/sdc1 /mnt/data

# DÃ©monter
sudo umount /mnt/data

# VÃ©rifier le montage automatique
cat /etc/fstab | grep sdc
```

---

**DerniÃ¨re mise Ã  jour** : 2026-01-17  
**Configuration testÃ©e** : HP Z800 + 3 disques (sda, sdb, sdc)  
**Disque utilisÃ©** : Intel SSD 149 GB (sdc1) montÃ© sur `/mnt/data`
```

**Message de commit :**
```
docs: configuration complÃ¨te du stockage sur disque sdc1
